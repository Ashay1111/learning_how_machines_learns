{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2084013,"sourceType":"datasetVersion","datasetId":1249555}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ashayjpatel/resnet-chest-xray-pneumonia-detection?scriptVersionId=287933268\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, models\nfrom sklearn.utils import class_weight\nimport numpy as np\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-22T12:41:13.920448Z","iopub.execute_input":"2025-12-22T12:41:13.921214Z","iopub.status.idle":"2025-12-22T12:41:13.925488Z","shell.execute_reply.started":"2025-12-22T12:41:13.92118Z","shell.execute_reply":"2025-12-22T12:41:13.924616Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Paths\nDATASET_DIR = \"/kaggle/input/chest-xray-images-guangzhou-women-and-childrens/chest_xray/\"\ntrain_dir = os.path.join(DATASET_DIR, \"train\")\ntest_dir  = os.path.join(DATASET_DIR, \"test\")\nIMG_SIZE = (224, 224)\nBATCH_SIZE = 32","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T12:41:50.483451Z","iopub.execute_input":"2025-12-22T12:41:50.483747Z","iopub.status.idle":"2025-12-22T12:41:50.487909Z","shell.execute_reply.started":"2025-12-22T12:41:50.483722Z","shell.execute_reply":"2025-12-22T12:41:50.487275Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#THE GENERATOR\ntrain_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input, # <--- The ResNet Way\n    validation_split=0.2,\n    # Add augmentation if you want (rotation, zoom, etc.)\n    rotation_range=20,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\ntest_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T12:41:57.650982Z","iopub.execute_input":"2025-12-22T12:41:57.651277Z","iopub.status.idle":"2025-12-22T12:41:57.655325Z","shell.execute_reply.started":"2025-12-22T12:41:57.651249Z","shell.execute_reply":"2025-12-22T12:41:57.654703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load data\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary',\n    subset='training'\n)\n\nval_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode='binary',\n    subset='validation'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T12:41:59.616761Z","iopub.execute_input":"2025-12-22T12:41:59.617472Z","iopub.status.idle":"2025-12-22T12:42:00.635651Z","shell.execute_reply.started":"2025-12-22T12:41:59.617444Z","shell.execute_reply":"2025-12-22T12:42:00.634958Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# THE MODEL\nbase_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\n# Freeze it\nbase_model.trainable = False\n\n# Add the Head \n# Note: ResNet often uses GlobalAveragePooling2D instead of Flatten, \n# because the feature maps are deeper (2048 channels).\nmodel = models.Sequential([\n    base_model,\n    layers.GlobalAveragePooling2D(), # Better than Flatten for ResNet\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.5), # ResNet is powerful, so we prevent overfitting\n    layers.Dense(1, activation='sigmoid')\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T12:43:33.455128Z","iopub.execute_input":"2025-12-22T12:43:33.455465Z","iopub.status.idle":"2025-12-22T12:43:34.514665Z","shell.execute_reply.started":"2025-12-22T12:43:33.455434Z","shell.execute_reply":"2025-12-22T12:43:34.51401Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Compile and Train\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# 1. Get all the labels from the generator\n# train_generator.classes gives an array like [0, 0, 1, 1, 1, 0...]\ntrain_labels = train_generator.classes\n\n# 2. Automatically calculate the weights\n# 'balanced' mode automatically adjusts weights inversely proportional to class frequencies\nclass_weights_array = class_weight.compute_class_weight(\n    class_weight='balanced',\n    classes=np.unique(train_labels),\n    y=train_labels\n)\n\n# 3. Convert to a dictionary (Keras requires a dictionary {0: weight, 1: weight})\nclass_weights = dict(enumerate(class_weights_array))\n\n# Print to verify\nprint(f\"Auto-Calculated Weights: {class_weights}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T12:43:36.821523Z","iopub.execute_input":"2025-12-22T12:43:36.822261Z","iopub.status.idle":"2025-12-22T12:43:36.870772Z","shell.execute_reply.started":"2025-12-22T12:43:36.822233Z","shell.execute_reply":"2025-12-22T12:43:36.870077Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    epochs=10, # Or whatever you choose\n    validation_data=val_generator,\n    class_weight=class_weights  \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T12:43:42.015569Z","iopub.execute_input":"2025-12-22T12:43:42.0165Z","iopub.status.idle":"2025-12-22T12:59:37.093453Z","shell.execute_reply.started":"2025-12-22T12:43:42.016471Z","shell.execute_reply":"2025-12-22T12:59:37.092703Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"ResNet_pneumonia_cnn.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T13:00:44.428449Z","iopub.execute_input":"2025-12-22T13:00:44.428801Z","iopub.status.idle":"2025-12-22T13:00:45.241588Z","shell.execute_reply.started":"2025-12-22T13:00:44.428771Z","shell.execute_reply":"2025-12-22T13:00:45.240725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_gen = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode=\"binary\",\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T13:07:24.59978Z","iopub.execute_input":"2025-12-22T13:07:24.600123Z","iopub.status.idle":"2025-12-22T13:07:24.796933Z","shell.execute_reply.started":"2025-12-22T13:07:24.600094Z","shell.execute_reply":"2025-12-22T13:07:24.796149Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Final evaluation (true test set)\ntest_gen.reset()\npred_probs = model.predict(test_gen)\npred_labels = (pred_probs > 0.1).astype(int).ravel()\ntrue_labels = test_gen.classes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T13:14:17.439931Z","iopub.execute_input":"2025-12-22T13:14:17.440514Z","iopub.status.idle":"2025-12-22T13:14:23.633451Z","shell.execute_reply.started":"2025-12-22T13:14:17.440484Z","shell.execute_reply":"2025-12-22T13:14:23.632539Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nprint(\n    classification_report(\n        true_labels,\n        pred_labels,\n        target_names=[\"Normal\", \"Pneumonia\"]\n    )\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T13:14:23.634774Z","iopub.execute_input":"2025-12-22T13:14:23.635016Z","iopub.status.idle":"2025-12-22T13:14:23.648241Z","shell.execute_reply.started":"2025-12-22T13:14:23.634994Z","shell.execute_reply":"2025-12-22T13:14:23.64768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\n\n# --- 1. THE ROBUST GRAD-CAM FUNCTION ---\ndef make_gradcam_heatmap_manual(img_array, model, pred_index=None):\n    #model.layers[0] is the ResNet50 Base\n    #model.layers[1:] are the Head (Pooling, Dense, Dropout, Dense)\n    \n    # Isolate the parts\n    base_model = model.layers[0]\n    classifier_layers = model.layers[1:]\n    \n    with tf.GradientTape() as tape:\n        # STEP 1: Run image through the Base (ResNet)\n        # We watch this output because we need its gradient\n        conv_outputs = base_model(img_array)\n        tape.watch(conv_outputs)\n        \n        # STEP 2: Run that output through the rest of the layers manually\n        preds = conv_outputs\n        for layer in classifier_layers:\n            preds = layer(preds)\n            \n        # Get the top predicted class\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # STEP 3: Gradient Calculation\n    # We want the gradient of the \"Prediction\" with respect to the \"ResNet Output\"\n    grads = tape.gradient(class_channel, conv_outputs)\n\n    # STEP 4: Global Average Pooling of Gradients\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # STEP 5: Weighting the Feature Map\n    # Multiply the feature map (conv_outputs) by the \"importance\" (pooled_grads)\n    conv_outputs = conv_outputs[0]\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    # Normalize\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\n# --- 2. RUN IT ---\n# Pick a test image (Pneumonia)\nimg_dir = '/kaggle/input/chest-xray-images-guangzhou-women-and-childrens/chest_xray/test/PNEUMONIA'\nimg_name = os.listdir(img_dir)[0]\nimg_path = os.path.join(img_dir, img_name)\n\n# Preprocess (ResNet Style)\nimg = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))\nimg_array = tf.keras.preprocessing.image.img_to_array(img)\nimg_array = np.expand_dims(img_array, axis=0)\nimg_array = tf.keras.applications.resnet50.preprocess_input(img_array)\n\n# Generate\nprint(\"Generating Heatmap...\")\nheatmap = make_gradcam_heatmap_manual(img_array, model)\n\n# --- 3. VISUALIZE ---\nimg_original = cv2.imread(img_path)\nimg_original = cv2.resize(img_original, (224, 224))\n\n# Colorize\nheatmap_resized = cv2.resize(heatmap, (224, 224))\nheatmap_resized = np.uint8(255 * heatmap_resized)\njet_heatmap = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n\n# Superimpose\nsuperimposed_img = jet_heatmap * 0.4 + img_original\nsuperimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n\n# Plot\nplt.figure(figsize=(12, 6))\nplt.subplot(1, 2, 1)\nplt.imshow(cv2.cvtColor(img_original, cv2.COLOR_BGR2RGB))\nplt.title(\"Original X-Ray\")\nplt.axis('off')\n\nplt.subplot(1, 2, 2)\nplt.imshow(superimposed_img)\nplt.title(\"ResNet50 Heatmap\")\nplt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-22T13:17:15.251787Z","iopub.execute_input":"2025-12-22T13:17:15.252072Z","iopub.status.idle":"2025-12-22T13:17:17.354647Z","shell.execute_reply.started":"2025-12-22T13:17:15.252047Z","shell.execute_reply":"2025-12-22T13:17:17.353955Z"}},"outputs":[],"execution_count":null}]}